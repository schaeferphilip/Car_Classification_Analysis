{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5871025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score, recall_score\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient \n",
    "import pickle\n",
    "import datetime as dt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492441d5",
   "metadata": {},
   "source": [
    "# Clients data non based on CO2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5618dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = pd.read_pickle('clients_labeled_cleaned_08_03_2023.pkl') \n",
    "X, y = clients.drop(columns=[\"label\"]), clients['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256490a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data preprocessor\n",
    "with open(\"data_transformer.pkl\", 'rb') as file:\n",
    "    transformer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38eacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70784d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da819582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_train, pred_train, y_test, pred_test, model=\"\", verbose=True) :\n",
    "    acc_train = accuracy_score(y_train, pred_train)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "    prec_train = precision_score(y_train, pred_train, average='macro')\n",
    "    prec_test = precision_score(y_test, pred_test, average='macro') \n",
    "    f1_train = f1_score(y_train, pred_train, average='micro')\n",
    "    f1_test = f1_score(y_test, pred_test, average='micro') \n",
    "\n",
    "    mlflow.log_metric(\"accuracy_train\", acc_train)\n",
    "    mlflow.log_metric(\"accuracy_test\", acc_test)\n",
    "    mlflow.log_metric(\"precision_train\", prec_train)\n",
    "    mlflow.log_metric(\"precision_test\", prec_test)\n",
    "    mlflow.log_metric(\"f1_score_train\", f1_train)\n",
    "    mlflow.log_metric(\"f1_score_test\", f1_test)\n",
    "\n",
    "    if(verbose):\n",
    "        display_metrics(acc_train, acc_test, prec_train, prec_test, f1_train, f1_test)\n",
    "\n",
    "\n",
    "def display_metrics(acc_train, acc_test, prec_train, prec_test, f1_train, f1_test):\n",
    "    print(f\"train accuracy : {acc_train*100:.2f}%\")\n",
    "    print(f\"test accuracy : {acc_test*100:.2f}%\")\n",
    "    print()\n",
    "    print(f\"train precision : {prec_train*100:.2f}%\")\n",
    "    print(f\"test precision : {prec_test*100:.2f}%\")\n",
    "    print()\n",
    "    print(f\"train f1 : {f1_train*100:.2f}%\")\n",
    "    print(f\"test f1 : {f1_test*100:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56391be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "p = {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "model1 = LogisticRegression(**p, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "p = {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "model2 = RandomForestClassifier(**p, bootstrap=True, n_jobs=-1, random_state=RANDOM_STATE) #bootsrap=Fasle : use all dataset to train each tree\n",
    "\n",
    "p =  {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200}\n",
    "model3 = XGBClassifier(**p, random_state=RANDOM_STATE)\n",
    "\n",
    "p = {'n_neighbors': 7, 'weights': 'uniform'}\n",
    "model5 = KNeighborsClassifier(n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754b64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 76.47%\n",
      "test accuracy : 71.51%\n",
      "\n",
      "train precision : 79.42%\n",
      "test precision : 72.67%\n",
      "\n",
      "train f1 : 76.47%\n",
      "test f1 : 71.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_ID = 2\n",
    "\n",
    "# Load expermient or create new\n",
    "experiment_name = 'experiment_'+ str(EXPERIMENT_ID)+ '_voting_clf_on_data_without_co2'\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment_id.experiment_id if experiment_id else mlflow.create_experiment(experiment_name)\n",
    "    \n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"voting_classifier_\" + str(dt.datetime.now())[0:-10] ) :  \n",
    "    # Define voting classifier and train\n",
    "    voting_classifier = VotingClassifier(estimators=[('lr', model1), ('rf', model2), ('ada', model3), ('knn', model5)], voting='soft')\n",
    "    voting_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = voting_classifier.predict(X_train)\n",
    "    pred_test = voting_classifier.predict(X_test)\n",
    "    \n",
    "    # compute and logs metrics for each model\n",
    "    compute_metrics(y_train, pred_train, y_test, pred_test, model=\"voting_clf\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(voting_classifier, \"voting_clf\")\n",
    "    mlflow.log_param(\"model\", \"voting_clf (logistic_regression - random_forest - adaboost - gaussian_nb - knn)\")\n",
    "    mlflow.set_tag('estimator_class', type(voting_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dbc01c",
   "metadata": {},
   "source": [
    "# Clients data based on CO2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d99537ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = pd.read_pickle('clients_labeled_cleaned_05_04_2023_co2_based.pkl') \n",
    "X, y = clients.drop(columns=[\"label\"]), clients['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5207d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d4f035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 73.25%\n",
      "test accuracy : 69.48%\n",
      "\n",
      "train precision : 70.16%\n",
      "test precision : 65.40%\n",
      "\n",
      "train f1 : 73.25%\n",
      "test f1 : 69.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_ID = 3\n",
    "# Load expermient or create new\n",
    "experiment_name = 'experiment_'+ str(EXPERIMENT_ID)+ '_voting_clf_on_data_with_co2'\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment_id.experiment_id if experiment_id else mlflow.create_experiment(experiment_name)\n",
    "    \n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"voting_classifier_\" + str(dt.datetime.now())[0:-10] ) :  \n",
    "    # Define voting classifier and train\n",
    "    voting_classifier = VotingClassifier(estimators=[('lr', model1), ('rf', model2), ('ada', model3), ('knn', model5)], voting='soft')\n",
    "    voting_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = voting_classifier.predict(X_train)\n",
    "    pred_test = voting_classifier.predict(X_test)\n",
    "    \n",
    "    # compute and logs metrics for each model\n",
    "    compute_metrics(y_train, pred_train, y_test, pred_test, model=\"voting_clf\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(voting_classifier, \"voting_clf\")\n",
    "    mlflow.log_param(\"model\", \"voting_clf (logistic_regression - random_forest - adaboost - gaussian_nb - knn)\")\n",
    "    mlflow.set_tag('estimator_class', type(voting_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d897f0",
   "metadata": {},
   "source": [
    "<font color=blue size=5>L'ajout des données de CO2 semble impacter négativement les perfomances des modèles </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9b81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
